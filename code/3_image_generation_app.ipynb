{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Image Generation App\n",
                "\n",
                "In this tutorial, you'll create an image generation app with a Gradio interface.\n",
                "\n",
                "*This tutorial is mainly based on an excellent course provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearning.AI.*\n",
                "\n",
                "# Setup\n",
                "\n",
                "## Python\n",
                "\n",
                "Load your HF API key and relevant Python libraries"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import os\n",
                "import io\n",
                "import IPython.display\n",
                "from PIL import Image\n",
                "import base64\n",
                "import gradio as gr\n",
                "import json\n",
                "from diffusers import DiffusionPipeline\n",
                "from dotenv import load_dotenv, find_dotenv\n",
                "_ = load_dotenv(find_dotenv())  # read local .env file\n",
                "hf_api_key = os.environ['HF_API_KEY']"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load model (only Apple Silicon)\n",
                "\n",
                "- In this example, we demonstrate how to use Stable Diffusion in Apple Silicon (M1/M2). \n",
                "- You'll find the Windows and Apple Intel version below.\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Apple Silicon version\n",
                "\n",
                "pipe = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
                "\n",
                "pipe = pipe.to(\"mps\")\n",
                "\n",
                "# Recommended if your computer has < 64 GB of RAM\n",
                "pipe.enable_attention_slicing()\n",
                "\n",
                "\n",
                "def get_completion(prompt):\n",
                "    return pipe(prompt).images[0]\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Model (only Apple Intel and Windows)"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "pipe = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
                "\n",
                "\n",
                "def get_completion(prompt):\n",
                "    return pipe(prompt).images[0]\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optional: API-version {.smaller}\n",
                "\n",
                "- Only use this code if you want to use the API\n",
                "\n",
                "```{Python}\n",
                "\n",
                "# Helper function\n",
                "import requests, json\n",
                "\n",
                "#Text-to-image endpoint\n",
                "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n",
                "    headers = {\n",
                "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
                "      \"Content-Type\": \"application/json\"\n",
                "    }   \n",
                "    data = { \"inputs\": inputs }\n",
                "    if parameters is not None:\n",
                "        data.update({\"parameters\": parameters})\n",
                "    response = requests.request(\"POST\",\n",
                "                                ENDPOINT_URL,\n",
                "                                headers=headers,\n",
                "                                data=json.dumps(data))\n",
                "    return json.loads(response.content.decode(\"utf-8\"))\n",
                "```\n",
                "\n",
                "\n",
                "# Image Generation App\n",
                "\n",
                "Building an image generation app \n",
                "\n",
                "## Example prompt\n",
                "\n",
                "- Here we are going to run `runwayml/stable-diffusion-v1-5` using the `ðŸ§¨ diffusers` library.\n",
                "\n",
                "\n",
                "\n",
                "```{Python}\n",
                "prompt = \"a dog in a park\"\n",
                "```\n",
                "\n",
                "## Result"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "result = get_completion(prompt)\n",
                "result"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](/images/dog_in_park.png)\n",
                "\n",
                "\n",
                "## Generating with `gr.Interface()` {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def generate(inputs):\n",
                "    output = get_completion(inputs)\n",
                "    return output\n",
                "\n",
                "\n",
                "gr.close_all()\n",
                "demo = gr.Interface(fn=generate,\n",
                "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
                "                    outputs=[gr.Image(label=\"Result\")],\n",
                "                    title=\"Image Generation with Stable Diffusion\",\n",
                "                    description=\"Generate any image with Stable Diffusion\",\n",
                "                    allow_flagging=\"never\",\n",
                "                    examples=[\n",
                "                        \"a scary cyborg wandering in the city of Stuttgart\", \"a red Jeep in a swimming pool\"]\n",
                "                    )\n",
                "\n",
                "demo.launch(share=True)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gradio user interface\n",
                "\n",
                "![](/images/image_gen_1.png)\n",
                "\n",
                "## Output\n",
                "\n",
                "![](/images/image_gen_2.png)\n",
                "\n",
                "\n",
                "## Optional: API-Version {.smaller}\n",
                "\n",
                "```{Python}\n",
                "import gradio as gr \n",
                "\n",
                "#A helper function to convert the PIL image to base64\n",
                "#so you can send it to the API\n",
                "def base64_to_pil(img_base64):\n",
                "    base64_decoded = base64.b64decode(img_base64)\n",
                "    byte_stream = io.BytesIO(base64_decoded)\n",
                "    pil_image = Image.open(byte_stream)\n",
                "    return pil_image\n",
                "\n",
                "def generate(prompt):\n",
                "    output = get_completion(prompt)\n",
                "    result_image = base64_to_pil(output)\n",
                "    return result_image\n",
                "\n",
                "gr.close_all()\n",
                "demo = gr.Interface(fn=generate,\n",
                "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
                "                    outputs=[gr.Image(label=\"Result\")],\n",
                "                    title=\"Image Generation with Stable Diffusion\",\n",
                "                    description=\"Generate any image with Stable Diffusion\",\n",
                "                    allow_flagging=\"never\",\n",
                "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
                "\n",
                "demo.launch(share=True, server_port=int(os.environ['PORT1']))\n",
                "```\n",
                "\n",
                "## Close apps"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "demo.close()"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced User Interface\n",
                "\n",
                "Building a more advanced interface\n",
                "\n",
                "## Gradio app  {.smaller}\n",
                "\n",
                "Note: The following code for the local app mimics the code of the API-version as close as possible. "
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def get_completion(inputs, parameters=None):\n",
                "    data = {\"inputs\": inputs}\n",
                "    if parameters is not None:\n",
                "        data.update({\"parameters\": parameters})\n",
                "    response = json.dumps(data)\n",
                "    return pipe(response).images[0]\n",
                "\n",
                "\n",
                "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
                "    params = {\n",
                "        \"negative_prompt\": negative_prompt,\n",
                "        \"num_inference_steps\": steps,\n",
                "        \"guidance_scale\": guidance,\n",
                "        \"width\": width,\n",
                "        \"height\": height\n",
                "    }\n",
                "\n",
                "    output = get_completion(prompt, params)\n",
                "    return output\n",
                "\n",
                "\n",
                "gr.close_all()\n",
                "demo = gr.Interface(fn=generate,\n",
                "                    inputs=[\n",
                "                        gr.Textbox(label=\"Your prompt\"),\n",
                "                        gr.Textbox(label=\"Negative prompt\"),\n",
                "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
                "                                  info=\"In how many steps will the denoiser denoise the image?\"),\n",
                "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
                "                                  info=\"Controls how much the text prompt influences the result\"),\n",
                "                        gr.Slider(label=\"Width\", minimum=64,\n",
                "                                  maximum=512, step=64, value=512),\n",
                "                        gr.Slider(label=\"Height\", minimum=64,\n",
                "                                  maximum=512, step=64, value=512),\n",
                "                    ],\n",
                "                    outputs=[gr.Image(label=\"Result\")],\n",
                "                    title=\"Image Generation with Stable Diffusion\",\n",
                "                    description=\"Generate any image with Stable Diffusion\",\n",
                "                    allow_flagging=\"never\"\n",
                "                    )\n",
                "\n",
                "demo.launch(share=True)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gradio user interface\n",
                "\n",
                "![](/images/image_gen_3.png)\n",
                "\n",
                "\n",
                "## Model output\n",
                "\n",
                "![](/images/image_gen_4.png)\n",
                "\n",
                "ðŸ¤”\n",
                "\n",
                "## Optional: API-version {.smaller}\n",
                "\n",
                "```{Python}\n",
                "\n",
                "#A helper function to convert the PIL image to base64 \n",
                "# so you can send it to the API\n",
                "def base64_to_pil(img_base64):\n",
                "    base64_decoded = base64.b64decode(img_base64)\n",
                "    byte_stream = io.BytesIO(base64_decoded)\n",
                "    pil_image = Image.open(byte_stream)\n",
                "    return pil_image\n",
                "\n",
                "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
                "    params = {\n",
                "        \"negative_prompt\": negative_prompt,\n",
                "        \"num_inference_steps\": steps,\n",
                "        \"guidance_scale\": guidance,\n",
                "        \"width\": width,\n",
                "        \"height\": height\n",
                "    }\n",
                "    \n",
                "    output = get_completion(prompt, params)\n",
                "    pil_image = base64_to_pil(output)\n",
                "    return pil_image\n",
                "\n",
                "gr.close_all()\n",
                "demo = gr.Interface(fn=generate,\n",
                "                    inputs=[\n",
                "                        gr.Textbox(label=\"Your prompt\"),\n",
                "                        gr.Textbox(label=\"Negative prompt\"),\n",
                "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
                "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
                "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n",
                "                                  info=\"Controls how much the text prompt influences the result\"),\n",
                "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
                "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
                "                    ],\n",
                "                    outputs=[gr.Image(label=\"Result\")],\n",
                "                    title=\"Image Generation with Stable Diffusion\",\n",
                "                    description=\"Generate any image with Stable Diffusion\",\n",
                "                    allow_flagging=\"never\"\n",
                "                    )\n",
                "\n",
                "demo.launch(share=True, server_port=int(os.environ['PORT2']))\n",
                "```\n",
                "\n",
                "## Close apps"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "demo.close()"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Gradio Blocks\n",
                "\n",
                "## Gradio example with Blocks {.smaller}\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "with gr.Blocks() as demo:\n",
                "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
                "    prompt = gr.Textbox(label=\"Your prompt\")\n",
                "    with gr.Row():\n",
                "        with gr.Column():\n",
                "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
                "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
                "                              info=\"In many steps will the denoiser denoise the image?\")\n",
                "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
                "                                 info=\"Controls how much the text prompt influences the result\")\n",
                "            width = gr.Slider(label=\"Width\", minimum=64,\n",
                "                              maximum=512, step=64, value=512)\n",
                "            height = gr.Slider(label=\"Height\", minimum=64,\n",
                "                               maximum=512, step=64, value=512)\n",
                "            btn = gr.Button(\"Submit\")\n",
                "        with gr.Column():\n",
                "            output = gr.Image(label=\"Result\")\n",
                "\n",
                "    btn.click(fn=generate, inputs=[\n",
                "              prompt, negative_prompt, steps, guidance, width, height], outputs=[output])\n",
                "gr.close_all()\n",
                "demo.launch(share=True)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gradio user interface\n",
                "\n",
                "![](/images/image_gen_5.png)\n",
                "\n",
                "## Optional: API Version {.smaller}\n",
                "\n",
                "```{Python}\n",
                "\n",
                "with gr.Blocks() as demo:\n",
                "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
                "    prompt = gr.Textbox(label=\"Your prompt\")\n",
                "    with gr.Row():\n",
                "        with gr.Column():\n",
                "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
                "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
                "                      info=\"In many steps will the denoiser denoise the image?\")\n",
                "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
                "                      info=\"Controls how much the text prompt influences the result\")\n",
                "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
                "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
                "            btn = gr.Button(\"Submit\")\n",
                "        with gr.Column():\n",
                "            output = gr.Image(label=\"Result\")\n",
                "\n",
                "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
                "gr.close_all()\n",
                "demo.launch(share=True, server_port=int(os.environ['PORT3']))\n",
                "\n",
                "```\n",
                "\n",
                "## Gradio app with drop down menu {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "with gr.Blocks() as demo:\n",
                "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
                "    with gr.Row():\n",
                "        with gr.Column(scale=4):\n",
                "            # Give prompt some real estate\n",
                "            prompt = gr.Textbox(label=\"Your prompt\")\n",
                "        with gr.Column(scale=1, min_width=50):\n",
                "            btn = gr.Button(\"Submit\")  # Submit button side by side!\n",
                "    with gr.Accordion(\"Advanced options\", open=False):  # Let's hide the advanced options!\n",
                "        negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
                "        with gr.Row():\n",
                "            with gr.Column():\n",
                "                steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
                "                                  info=\"In many steps will the denoiser denoise the image?\")\n",
                "                guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
                "                                     info=\"Controls how much the text prompt influences the result\")\n",
                "            with gr.Column():\n",
                "                width = gr.Slider(label=\"Width\", minimum=64,\n",
                "                                  maximum=512, step=64, value=512)\n",
                "                height = gr.Slider(label=\"Height\", minimum=64,\n",
                "                                   maximum=512, step=64, value=512)\n",
                "    output = gr.Image(label=\"Result\")  # Move the output up too\n",
                "\n",
                "    btn.click(fn=generate, inputs=[\n",
                "              prompt, negative_prompt, steps, guidance, width, height], outputs=[output])\n",
                "\n",
                "gr.close_all()\n",
                "demo.launch(share=True)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gradio user interface\n",
                "\n",
                "![](/images/gradio_app_7.png)\n",
                "\n",
                "\n",
                "## Optional: API Version  {.smaller}\n",
                "\n",
                "```{Python}\n",
                "with gr.Blocks() as demo:\n",
                "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
                "    with gr.Row():\n",
                "        with gr.Column(scale=4):\n",
                "            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
                "        with gr.Column(scale=1, min_width=50):\n",
                "            btn = gr.Button(\"Submit\") #Submit button side by side!\n",
                "    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
                "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
                "            with gr.Row():\n",
                "                with gr.Column():\n",
                "                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
                "                      info=\"In many steps will the denoiser denoise the image?\")\n",
                "                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
                "                      info=\"Controls how much the text prompt influences the result\")\n",
                "                with gr.Column():\n",
                "                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
                "                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
                "    output = gr.Image(label=\"Result\") #Move the output up too\n",
                "            \n",
                "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
                "\n",
                "gr.close_all()\n",
                "demo.launch(share=True, server_port=int(os.environ['PORT4']))\n",
                "```\n",
                "\n",
                "## Close all apps"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "gr.close_all()"
            ],
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "language": "python",
            "display_name": "Python 3 (ipykernel)"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}