[
  {
    "objectID": "requirements.html",
    "href": "requirements.html",
    "title": "Requirements",
    "section": "",
    "text": "To start this lab, you‚Äôll need:\n\n\n\n\n\n\nImportant\n\n\n\nVisit the ‚ÄúProgramming Toolkit-webpage‚Äù to learn how to meet all requirements.\n\n\n\nPython: Anaconda, Anaconda Environment prompt and Visual Studio Code\nEnvironment: A folder on your machine called prompt, an OpenAI-API key and an environment file with your OpenAI-API keyqu\nBasic knowledge about HuggingFace and some NLP tasks: Text summarization,"
  },
  {
    "objectID": "code/notebook.html",
    "href": "code/notebook.html",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#setup",
    "href": "code/notebook.html#setup",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#data",
    "href": "code/notebook.html#data",
    "title": "Notebook",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "This is a Quarto slidedeck."
  },
  {
    "objectID": "slide.html",
    "href": "slide.html",
    "title": "Slides",
    "section": "",
    "text": "For cost reasons we mainly use OpenAI‚Äôs gpt-3.5-turbo model in our tutorials. However, you can simply replace model=\"gpt-3.5-turbo\" with model=\"gpt-4\" in the helper function. Note the price difference between the two models."
  },
  {
    "objectID": "slide.html#guidelines",
    "href": "slide.html#guidelines",
    "title": "Slides",
    "section": "1 Guidelines",
    "text": "1 Guidelines\nIn this tutorial, you‚Äôll practice two prompting principles and their related tactics in order to write effective prompts for large language models:\n\nüñ•Ô∏è Guidelines"
  },
  {
    "objectID": "slide.html#iterative-prompt-development",
    "href": "slide.html#iterative-prompt-development",
    "title": "Slides",
    "section": "2 Iterative prompt development",
    "text": "2 Iterative prompt development\nIn this tutorial, you‚Äôll iteratively analyze and refine your prompts to generate marketing copy from a product fact sheet.\n\nüñ•Ô∏è Iterative prompt development"
  },
  {
    "objectID": "slide.html#summarize-text",
    "href": "slide.html#summarize-text",
    "title": "Slides",
    "section": "3 Summarize text",
    "text": "3 Summarize text\nIn this tutorial, you will summarize text with a focus on specific topics.\n\nüñ•Ô∏è Summarize text"
  },
  {
    "objectID": "slide.html#inferring",
    "href": "slide.html#inferring",
    "title": "Slides",
    "section": "4 Inferring",
    "text": "4 Inferring\nIn this tutorial, you will infer sentiment and topics from product reviews and news articles.\n\nüñ•Ô∏è Inferring"
  },
  {
    "objectID": "slide.html#transforming",
    "href": "slide.html#transforming",
    "title": "Slides",
    "section": "5 Transforming",
    "text": "5 Transforming\nIn this presentation, we will explore how to use Large Language Models for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion.\n\nüñ•Ô∏è Transforming"
  },
  {
    "objectID": "slide.html#expanding",
    "href": "slide.html#expanding",
    "title": "Slides",
    "section": "6 Expanding",
    "text": "6 Expanding\nIn this tutorial, you will generate customer service emails that are tailored to each customer‚Äôs review.\n\nüñ•Ô∏è Expanding"
  },
  {
    "objectID": "slide.html#chatbot",
    "href": "slide.html#chatbot",
    "title": "Slides",
    "section": "7 Chatbot",
    "text": "7 Chatbot\nIn this presentation, you will explore how you can utilize the chat format to have extended conversations with chatbots personalized or specialized for specific tasks or behaviors.\nWe use Panel, an open-source Python library that lets you easily build powerful tools, dashboards and complex applications entirely in Python.\n\nüñ•Ô∏è Chatbot"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome üëã",
    "section": "",
    "text": "Welcome to the lab ‚Äúprompt engineering‚Äù\n\nIn this lab, we will use OpenAI‚Äôs API to leverage Large Language Models (LLMs) like GPT-3.5 Turbo and GPT-4 into custom Python applications, and learn how to build our own chatbot.\n\n\n\n\n\n\nImportant\n\n\n\nMake sure you meet all the requirements and have read the lecture slides before you start with the assignments\n\n\nWhat you will learn in this lab:\n\nYou‚Äôll practice prompting principles and their related tactics\nHow to analyze and refine your prompts to generate marketing copy from a product fact sheet.\nSummarize text with a focus on specific topics.\nInfer sentiment and topics from product reviews and news articles.\nExplore how to use Large Language Models for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion.\nGenerate customer service emails that are tailored to each customer‚Äôs review.\nHow you can utilize the chat format to have extended conversations with chatbots personalized or specialized for specific tasks or behaviors.\n\n\nThis lab is mainly based on an excellent course provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearning.AI."
  },
  {
    "objectID": "slides/1_nlp_apps.html#python",
    "href": "slides/1_nlp_apps.html#python",
    "title": "Simple Gradio NLP Apps",
    "section": "Python",
    "text": "Python\n\nimport gradio as gr\nfrom transformers import pipeline\nimport os\nimport io\nfrom IPython.display import Image, display, HTML\nfrom PIL import Image\nimport base64\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nhf_api_key = os.environ['HF_API_KEY']  # HuggingFace API"
  },
  {
    "objectID": "slides/1_nlp_apps.html#text-summarization",
    "href": "slides/1_nlp_apps.html#text-summarization",
    "title": "Simple Gradio NLP Apps",
    "section": "Text summarization",
    "text": "Text summarization\n\nTo learn more about text summarization, take a look at this tutorial"
  },
  {
    "objectID": "slides/1_nlp_apps.html#helper-function-summarization-pipeline",
    "href": "slides/1_nlp_apps.html#helper-function-summarization-pipeline",
    "title": "Simple Gradio NLP Apps",
    "section": "Helper function: summarization pipeline",
    "text": "Helper function: summarization pipeline\n\nget_completion = pipeline(\n    \"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")"
  },
  {
    "objectID": "slides/1_nlp_apps.html#api-version",
    "href": "slides/1_nlp_apps.html#api-version",
    "title": "Simple Gradio NLP Apps",
    "section": "API-version",
    "text": "API-version\n\nThe code would look very similar if you were running it from an API instead of locally.\nThe same is true for all the tutorials in the rest of the course, make sure to check the Pipelines documentation page"
  },
  {
    "objectID": "slides/1_nlp_apps.html#api-code",
    "href": "slides/1_nlp_apps.html#api-code",
    "title": "Simple Gradio NLP Apps",
    "section": "API code",
    "text": "API code\n\nIn our example: to run it via API, you could use an Inference Endpoint for the sshleifer/distilbart-cnn-12-6, a 306M parameter distilled model from facebook/bart-large-cnn.\n\n\n\n# # Helper function\n# import requests, json\n\n\n# #Summarization endpoint\n# def get_completion(inputs, parameters=None,ENDPOINT_URL=os.environ['HF_API_SUMMARY_BASE']):\n#     headers = {\n#       \"Authorization\": f\"Bearer {hf_api_key}\",\n#       \"Content-Type\": \"application/json\"\n#     }\n#     data = { \"inputs\": inputs }\n#     if parameters is not None:\n#         data.update({\"parameters\": parameters})\n#     response = requests.request(\"POST\",\n#                                 ENDPOINT_URL, headers=headers,\n#                                 data=json.dumps(data)\n#                                )\n#     return json.loads(response.content.decode(\"utf-8\"))"
  },
  {
    "objectID": "slides/1_nlp_apps.html#text-to-summarize",
    "href": "slides/1_nlp_apps.html#text-to-summarize",
    "title": "Simple Gradio NLP Apps",
    "section": "Text to summarize",
    "text": "Text to summarize\n\ntext = ('''One of the best ways to share your machine learning model, API, or data science workflow with others is to create an interactive app that allows your users or colleagues to try out the demo in their browsers. Gradio allows you to build demos and share them, all in Python. And usually in just a few lines of code! Note that we shorten the imported name gradio to gr for better readability of code using Gradio. This is a widely adopted convention that you should follow so that anyone working with your code can easily understand it. You‚Äôll also notice that in order to make apps, we create a gr.Interface. This Interface class can wrap any Python function with a user interface. The core Interface class is initialized with three required parameters: fn: the function to wrap a UI around; inputs: which component(s) to use for the input (e.g. \"text\", \"image\" or \"audio\"); outputs: which component(s) to use for the output (e.g. \"text\", \"image\" or \"label\") ''')"
  },
  {
    "objectID": "slides/1_nlp_apps.html#summarization-example",
    "href": "slides/1_nlp_apps.html#summarization-example",
    "title": "Simple Gradio NLP Apps",
    "section": "Summarization example",
    "text": "Summarization example\n\ndef summarize(input):\n    output = get_completion(input)\n    return output[0]['summary_text']\n\n\nsummarize(text)"
  },
  {
    "objectID": "slides/1_nlp_apps.html#summarization-example-output",
    "href": "slides/1_nlp_apps.html#summarization-example-output",
    "title": "Simple Gradio NLP Apps",
    "section": "Summarization example",
    "text": "Summarization example"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-app-code",
    "href": "slides/1_nlp_apps.html#gradio-app-code",
    "title": "Simple Gradio NLP Apps",
    "section": "Gradio app code",
    "text": "Gradio app code\n\nGetting started with Gradio gr.Interface\nIf you want to use the API-version, replace demo.launch(share=False) with demo.launch(share=True, server_port=int(os.environ['PORT1']))\n\n\n\n# Helper function\n\n\ndef summarize(input):\n    output = get_completion(input)\n    return output[0]['summary_text']\n\n\n# Close all current apps\ngr.close_all()\n\n# Start of the app\ndemo = gr.Interface(\n    fn=summarize,\n    inputs=\"text\",\n    outputs=\"text\",\n    examples=[\"One of the best ways to share your machine learning model, API, or data science workflow with others is to create an interactive app that allows your users or colleagues to try out the demo in their browsers. Gradio allows you to build demos and share them, all in Python. And usually in just a few lines of code! Note that we shorten the imported name gradio to gr for better readability of code using Gradio. This is a widely adopted convention that you should follow so that anyone working with your code can easily understand it. You‚Äôll also notice that in order to make apps, we create a gr.Interface. This Interface class can wrap any Python function with a user interface\"]\n)\n\ndemo.launch(share=False)"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-interface",
    "href": "slides/1_nlp_apps.html#gradio-interface",
    "title": "Simple Gradio NLP Apps",
    "section": "Gradio interface",
    "text": "Gradio interface"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-with-text-input",
    "href": "slides/1_nlp_apps.html#gradio-with-text-input",
    "title": "Simple Gradio NLP Apps",
    "section": "Gradio with text input",
    "text": "Gradio with text input"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-with-output",
    "href": "slides/1_nlp_apps.html#gradio-with-output",
    "title": "Simple Gradio NLP Apps",
    "section": "Gradio with output",
    "text": "Gradio with output"
  },
  {
    "objectID": "slides/1_nlp_apps.html#extended-gradio-app-code",
    "href": "slides/1_nlp_apps.html#extended-gradio-app-code",
    "title": "Simple Gradio NLP Apps",
    "section": "Extended Gradio app code",
    "text": "Extended Gradio app code\n\nWe include more text in the user interface\ndemo.launch(share=True) creates a public link to share the app.\n\n\n\ndef summarize(input):\n    output = get_completion(input)\n    return output[0]['summary_text']\n\n\ngr.close_all()\ndemo = gr.Interface(fn=summarize,\n                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n                    title=\"Text summarization with distilbart-cnn\",\n                    description=\"Summarize any text using the `sshleifer/distilbart-cnn-12-6` model under the hood!\"\n                    )\n\ndemo.launch(share=True)\n\n# API-Version\n# demo.launch(share=True, server_port=int(os.environ['PORT2']))"
  },
  {
    "objectID": "slides/1_nlp_apps.html#extended-gradio-output",
    "href": "slides/1_nlp_apps.html#extended-gradio-output",
    "title": "Simple Gradio NLP Apps",
    "section": "Extended Gradio output",
    "text": "Extended Gradio output"
  },
  {
    "objectID": "slides/1_nlp_apps.html#what-is-entity-recognition",
    "href": "slides/1_nlp_apps.html#what-is-entity-recognition",
    "title": "Simple Gradio NLP Apps",
    "section": "What is entity recognition?",
    "text": "What is entity recognition?\n\nNamed entity recognition (NER): Find the entities (such as persons, locations, or organizations) in a sentence.\nThis can be formulated as attributing a label to each token by having one class per entity and one class for ‚Äúno entity.‚Äù"
  },
  {
    "objectID": "slides/1_nlp_apps.html#helper-function-named-entity-recognition-pipeline",
    "href": "slides/1_nlp_apps.html#helper-function-named-entity-recognition-pipeline",
    "title": "Simple Gradio NLP Apps",
    "section": "Helper function: Named entity recognition pipeline",
    "text": "Helper function: Named entity recognition pipeline\n\nget_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")"
  },
  {
    "objectID": "slides/1_nlp_apps.html#api-version-1",
    "href": "slides/1_nlp_apps.html#api-version-1",
    "title": "Simple Gradio NLP Apps",
    "section": "API-Version",
    "text": "API-Version\n\nIf you want to use the Inference Endpoint for dslim/bert-base-NER, a 108M parameter fine-tuned BART model on the NER task:\n\n\n\n# API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n# get_completion(text, parameters=None, ENDPOINT_URL= API_URL)\n\n# API-Version\n# def ner(input):\n#     output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n#     return {\"text\": input, \"entities\": output}"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-ner-app",
    "href": "slides/1_nlp_apps.html#gradio-ner-app",
    "title": "Simple Gradio NLP Apps",
    "section": "Gradio NER App",
    "text": "Gradio NER App\n\ndef ner(input):\n    output = get_completion(input)\n    return {\"text\": input, \"entities\": output}\n\n\ngr.close_all()\n\ndemo = gr.Interface(fn=ner,\n                    inputs=[gr.Textbox(\n                        label=\"Text to find entities\", lines=2)],\n                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n                    title=\"NER with dslim/bert-base-NER\",\n                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n                    allow_flagging=\"never\",\n                    # Here we introduce a new tag, examples, easy to use examples for your application\n                    examples=[\"My name is Jan, I'm a professor at HdM Stuttgart and I live in Stuttgart\", \"My name is Lina and I study at HdM Stuttgart\"])\n\ndemo.launch(share=True)\n\n# API-Version\n# demo.launch(share=True, server_port=int(os.environ['PORT3']))"
  },
  {
    "objectID": "slides/1_nlp_apps.html#app-interface",
    "href": "slides/1_nlp_apps.html#app-interface",
    "title": "Simple Gradio NLP Apps",
    "section": "App interface",
    "text": "App interface"
  },
  {
    "objectID": "slides/1_nlp_apps.html#app-with-output",
    "href": "slides/1_nlp_apps.html#app-with-output",
    "title": "Simple Gradio NLP Apps",
    "section": "App with output",
    "text": "App with output"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-ner-app-with-merged-tokens",
    "href": "slides/1_nlp_apps.html#gradio-ner-app-with-merged-tokens",
    "title": "Simple Gradio NLP Apps",
    "section": "Gradio NER app with merged tokens",
    "text": "Gradio NER app with merged tokens\n\ndef merge_tokens(tokens):\n    merged_tokens = []\n    for token in tokens:\n        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n            # If current token continues the entity of the last one, merge them\n            last_token = merged_tokens[-1]\n            last_token['word'] += token['word'].replace('##', '')\n            last_token['end'] = token['end']\n            last_token['score'] = (last_token['score'] + token['score']) / 2\n        else:\n            # Otherwise, add the token to the list\n            merged_tokens.append(token)\n\n    return merged_tokens\n\n\ndef ner(input):\n    output = get_completion(input)\n    merged_tokens = merge_tokens(output)\n    return {\"text\": input, \"entities\": merged_tokens}\n\n\ngr.close_all()\ndemo = gr.Interface(fn=ner,\n                    inputs=[gr.Textbox(\n                        label=\"Text to find entities\", lines=2)],\n                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n                    title=\"NER with dslim/bert-base-NER\",\n                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n                    allow_flagging=\"never\",\n                    examples=[\"My name is Jan, I'm a professor at HdM Stuttgart and I live in Stuttgart\", \"My name is Lina, I live in Stuttgart and study at HdM Stuttgart\"])\n\ndemo.launch(share=True)\n\n# API-Version\n# demo.launch(share=True, server_port=int(os.environ['PORT4']))"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-output",
    "href": "slides/1_nlp_apps.html#gradio-output",
    "title": "Simple Gradio NLP Apps",
    "section": "Gradio output",
    "text": "Gradio output"
  },
  {
    "objectID": "slides/1_nlp_apps.html#close-all-apps",
    "href": "slides/1_nlp_apps.html#close-all-apps",
    "title": "Simple Gradio NLP Apps",
    "section": "Close all apps",
    "text": "Close all apps\n\ngr.close_all()"
  }
]