[
  {
    "objectID": "slides/1_nlp_apps.html#python",
    "href": "slides/1_nlp_apps.html#python",
    "title": "Gradio NLP Apps",
    "section": "Python",
    "text": "Python\n\nimport gradio as gr\nfrom transformers import pipeline\nimport os\nimport io\nfrom IPython.display import Image, display, HTML\nfrom PIL import Image\nimport base64\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nhf_api_key = os.environ['HF_API_KEY']  # HuggingFace API"
  },
  {
    "objectID": "slides/1_nlp_apps.html#text-summarization",
    "href": "slides/1_nlp_apps.html#text-summarization",
    "title": "Gradio NLP Apps",
    "section": "Text summarization",
    "text": "Text summarization\n\nTo learn more about text summarization, take a look at this tutorial"
  },
  {
    "objectID": "slides/1_nlp_apps.html#helper-function-summarization-pipeline",
    "href": "slides/1_nlp_apps.html#helper-function-summarization-pipeline",
    "title": "Gradio NLP Apps",
    "section": "Helper function: summarization pipeline",
    "text": "Helper function: summarization pipeline\n\nget_completion = pipeline(\n    \"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")"
  },
  {
    "objectID": "slides/1_nlp_apps.html#api-version",
    "href": "slides/1_nlp_apps.html#api-version",
    "title": "Gradio NLP Apps",
    "section": "API-version",
    "text": "API-version\n\nThe code would look very similar if you were running it from an API instead of locally.\nThe same is true for all the tutorials in the rest of the course, make sure to check the Pipelines documentation page"
  },
  {
    "objectID": "slides/1_nlp_apps.html#api-code",
    "href": "slides/1_nlp_apps.html#api-code",
    "title": "Gradio NLP Apps",
    "section": "API code",
    "text": "API code\n\nIn our example: to run it via API, you could use an Inference Endpoint for the sshleifer/distilbart-cnn-12-6, a 306M parameter distilled model from facebook/bart-large-cnn.\n\n\n\n# # Helper function\n# import requests, json\n\n\n# #Summarization endpoint\n# def get_completion(inputs, parameters=None,ENDPOINT_URL=os.environ['HF_API_SUMMARY_BASE']):\n#     headers = {\n#       \"Authorization\": f\"Bearer {hf_api_key}\",\n#       \"Content-Type\": \"application/json\"\n#     }\n#     data = { \"inputs\": inputs }\n#     if parameters is not None:\n#         data.update({\"parameters\": parameters})\n#     response = requests.request(\"POST\",\n#                                 ENDPOINT_URL, headers=headers,\n#                                 data=json.dumps(data)\n#                                )\n#     return json.loads(response.content.decode(\"utf-8\"))"
  },
  {
    "objectID": "slides/1_nlp_apps.html#text-to-summarize",
    "href": "slides/1_nlp_apps.html#text-to-summarize",
    "title": "Gradio NLP Apps",
    "section": "Text to summarize",
    "text": "Text to summarize\n\ntext = ('''One of the best ways to share your machine learning model, API, or data science workflow with others is to create an interactive app that allows your users or colleagues to try out the demo in their browsers. Gradio allows you to build demos and share them, all in Python. And usually in just a few lines of code! Note that we shorten the imported name gradio to gr for better readability of code using Gradio. This is a widely adopted convention that you should follow so that anyone working with your code can easily understand it. You’ll also notice that in order to make apps, we create a gr.Interface. This Interface class can wrap any Python function with a user interface. The core Interface class is initialized with three required parameters: fn: the function to wrap a UI around; inputs: which component(s) to use for the input (e.g. \"text\", \"image\" or \"audio\"); outputs: which component(s) to use for the output (e.g. \"text\", \"image\" or \"label\") ''')"
  },
  {
    "objectID": "slides/1_nlp_apps.html#summarization-example",
    "href": "slides/1_nlp_apps.html#summarization-example",
    "title": "Gradio NLP Apps",
    "section": "Summarization example",
    "text": "Summarization example\n\ndef summarize(input):\n    output = get_completion(input)\n    return output[0]['summary_text']\n\n\nsummarize(text)\n\n\n’ Gradio allows you to build demos and share them in just a few lines of code . The core Interface class is initialized with three required parameters: fn: the function to wrap a UI around; inputs: which component(s) to use for the input (e.g. “text”, “image” or “audio) or”label”)’"
  },
  {
    "objectID": "slides/1_nlp_apps.html#summarization-example-output",
    "href": "slides/1_nlp_apps.html#summarization-example-output",
    "title": "Gradio NLP Apps",
    "section": "Summarization example",
    "text": "Summarization example"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-app-code",
    "href": "slides/1_nlp_apps.html#gradio-app-code",
    "title": "Gradio NLP Apps",
    "section": "Gradio app code",
    "text": "Gradio app code\n\nGetting started with Gradio gr.Interface\nIf you want to use the API-version, replace demo.launch(share=False) with demo.launch(share=True, server_port=int(os.environ['PORT1']))\n\n\n\n# Helper function\n\n\ndef summarize(input):\n    output = get_completion(input)\n    return output[0]['summary_text']\n\n\n# Close all current apps\ngr.close_all()\n\n# Start of the app\ndemo = gr.Interface(\n    fn=summarize,\n    inputs=\"text\",\n    outputs=\"text\",\n    examples=[\"One of the best ways to share your machine learning model, API, or data science workflow with others is to create an interactive app that allows your users or colleagues to try out the demo in their browsers. Gradio allows you to build demos and share them, all in Python. And usually in just a few lines of code! Note that we shorten the imported name gradio to gr for better readability of code using Gradio. This is a widely adopted convention that you should follow so that anyone working with your code can easily understand it. You’ll also notice that in order to make apps, we create a gr.Interface. This Interface class can wrap any Python function with a user interface\"]\n)\n\ndemo.launch(share=False)"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-interface",
    "href": "slides/1_nlp_apps.html#gradio-interface",
    "title": "Gradio NLP Apps",
    "section": "Gradio interface",
    "text": "Gradio interface"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-with-text-input",
    "href": "slides/1_nlp_apps.html#gradio-with-text-input",
    "title": "Gradio NLP Apps",
    "section": "Gradio with text input",
    "text": "Gradio with text input"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-with-output",
    "href": "slides/1_nlp_apps.html#gradio-with-output",
    "title": "Gradio NLP Apps",
    "section": "Gradio with output",
    "text": "Gradio with output"
  },
  {
    "objectID": "slides/1_nlp_apps.html#extended-gradio-app-code",
    "href": "slides/1_nlp_apps.html#extended-gradio-app-code",
    "title": "Gradio NLP Apps",
    "section": "Extended Gradio app code",
    "text": "Extended Gradio app code\n\nWe include more text in the user interface\ndemo.launch(share=True) creates a public link to share the app.\n\n\n\ndef summarize(input):\n    output = get_completion(input)\n    return output[0]['summary_text']\n\n\ngr.close_all()\ndemo = gr.Interface(fn=summarize,\n                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n                    title=\"Text summarization with distilbart-cnn\",\n                    description=\"Summarize any text using the `sshleifer/distilbart-cnn-12-6` model under the hood!\"\n                    )\n\ndemo.launch(share=True)\n\n# API-Version\n# demo.launch(share=True, server_port=int(os.environ['PORT2']))"
  },
  {
    "objectID": "slides/1_nlp_apps.html#extended-gradio-output",
    "href": "slides/1_nlp_apps.html#extended-gradio-output",
    "title": "Gradio NLP Apps",
    "section": "Extended Gradio output",
    "text": "Extended Gradio output"
  },
  {
    "objectID": "slides/1_nlp_apps.html#what-is-entity-recognition",
    "href": "slides/1_nlp_apps.html#what-is-entity-recognition",
    "title": "Gradio NLP Apps",
    "section": "What is entity recognition?",
    "text": "What is entity recognition?\n\nNamed entity recognition (NER): Find the entities (such as persons, locations, or organizations) in a sentence.\nThis can be formulated as attributing a label to each token by having one class per entity and one class for “no entity.”"
  },
  {
    "objectID": "slides/1_nlp_apps.html#helper-function-named-entity-recognition-pipeline",
    "href": "slides/1_nlp_apps.html#helper-function-named-entity-recognition-pipeline",
    "title": "Gradio NLP Apps",
    "section": "Helper function: Named entity recognition pipeline",
    "text": "Helper function: Named entity recognition pipeline\n\nget_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")"
  },
  {
    "objectID": "slides/1_nlp_apps.html#api-version-1",
    "href": "slides/1_nlp_apps.html#api-version-1",
    "title": "Gradio NLP Apps",
    "section": "API-Version",
    "text": "API-Version\n\nIf you want to use the Inference Endpoint for dslim/bert-base-NER, a 108M parameter fine-tuned BART model on the NER task:\n\n\n\n# API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n# get_completion(text, parameters=None, ENDPOINT_URL= API_URL)\n\n# API-Version\n# def ner(input):\n#     output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n#     return {\"text\": input, \"entities\": output}"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-ner-app",
    "href": "slides/1_nlp_apps.html#gradio-ner-app",
    "title": "Gradio NLP Apps",
    "section": "Gradio NER App",
    "text": "Gradio NER App\n\ndef ner(input):\n    output = get_completion(input)\n    return {\"text\": input, \"entities\": output}\n\n\ngr.close_all()\n\ndemo = gr.Interface(fn=ner,\n                    inputs=[gr.Textbox(\n                        label=\"Text to find entities\", lines=2)],\n                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n                    title=\"NER with dslim/bert-base-NER\",\n                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n                    allow_flagging=\"never\",\n                    # Here we introduce a new tag, examples, easy to use examples for your application\n                    examples=[\"My name is Jan, I'm a professor at HdM Stuttgart and I live in Stuttgart\", \"My name is Lina and I study at HdM Stuttgart\"])\n\ndemo.launch(share=True)\n\n# API-Version\n# demo.launch(share=True, server_port=int(os.environ['PORT3']))"
  },
  {
    "objectID": "slides/1_nlp_apps.html#app-interface",
    "href": "slides/1_nlp_apps.html#app-interface",
    "title": "Gradio NLP Apps",
    "section": "App interface",
    "text": "App interface"
  },
  {
    "objectID": "slides/1_nlp_apps.html#app-with-output",
    "href": "slides/1_nlp_apps.html#app-with-output",
    "title": "Gradio NLP Apps",
    "section": "App with output",
    "text": "App with output"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-ner-app-with-merged-tokens",
    "href": "slides/1_nlp_apps.html#gradio-ner-app-with-merged-tokens",
    "title": "Gradio NLP Apps",
    "section": "Gradio NER app with merged tokens",
    "text": "Gradio NER app with merged tokens\n\ndef merge_tokens(tokens):\n    merged_tokens = []\n    for token in tokens:\n        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n            # If current token continues the entity of the last one, merge them\n            last_token = merged_tokens[-1]\n            last_token['word'] += token['word'].replace('##', '')\n            last_token['end'] = token['end']\n            last_token['score'] = (last_token['score'] + token['score']) / 2\n        else:\n            # Otherwise, add the token to the list\n            merged_tokens.append(token)\n\n    return merged_tokens\n\n\ndef ner(input):\n    output = get_completion(input)\n    merged_tokens = merge_tokens(output)\n    return {\"text\": input, \"entities\": merged_tokens}\n\n\ngr.close_all()\ndemo = gr.Interface(fn=ner,\n                    inputs=[gr.Textbox(\n                        label=\"Text to find entities\", lines=2)],\n                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n                    title=\"NER with dslim/bert-base-NER\",\n                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n                    allow_flagging=\"never\",\n                    examples=[\"My name is Jan, I'm a professor at HdM Stuttgart and I live in Stuttgart\", \"My name is Lina, I live in Stuttgart and study at HdM Stuttgart\"])\n\ndemo.launch(share=True)\n\n# API-Version\n# demo.launch(share=True, server_port=int(os.environ['PORT4']))"
  },
  {
    "objectID": "slides/1_nlp_apps.html#gradio-output",
    "href": "slides/1_nlp_apps.html#gradio-output",
    "title": "Gradio NLP Apps",
    "section": "Gradio output",
    "text": "Gradio output"
  },
  {
    "objectID": "slides/1_nlp_apps.html#close-all-apps",
    "href": "slides/1_nlp_apps.html#close-all-apps",
    "title": "Gradio NLP Apps",
    "section": "Close all apps",
    "text": "Close all apps\n\ngr.close_all()"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#setup",
    "href": "slides/2_image_captioning_app.html#setup",
    "title": "Gradio Image Captioning App",
    "section": "Setup",
    "text": "Setup"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#python",
    "href": "slides/2_image_captioning_app.html#python",
    "title": "Gradio Image Captioning App",
    "section": "Python",
    "text": "Python\nLoad your HF API key and relevant Python libraries.\n\nimport gradio as gr\nimport os\nimport io\nimport requests\nimport json\nimport IPython.display\nfrom PIL import Image\nimport base64\nfrom transformers import pipeline\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\nhf_api_key = os.environ['HF_API_KEY']"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#image-captioning-model",
    "href": "slides/2_image_captioning_app.html#image-captioning-model",
    "title": "Gradio Image Captioning App",
    "section": "Image captioning model",
    "text": "Image captioning model\n\nHere we’ll be using the Salesforce/blip-image-captioning-base a 14M parameter captioning model.\n\n\nget_completion = pipeline(\n    \"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n\n\ndef summarize(input):\n    output = get_completion(input)\n    return output[0]['generated_text']"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#api-code-optional",
    "href": "slides/2_image_captioning_app.html#api-code-optional",
    "title": "Gradio Image Captioning App",
    "section": "API-code (optional)",
    "text": "API-code (optional)\n\nOptional: Here is the code for the API-version:\n\n\n# Image-to-text endpoint (with API)\n# def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']):\n#     headers = {\n#       \"Authorization\": f\"Bearer {hf_api_key}\",\n#       \"Content-Type\": \"application/json\"\n#     }\n#     data = { \"inputs\": inputs }\n#     if parameters is not None:\n#         data.update({\"parameters\": parameters})\n#     response = requests.request(\"POST\",\n#                                 ENDPOINT_URL,\n#                                 headers=headers,\n#                                 data=json.dumps(data))\n#     return json.loads(response.content.decode(\"utf-8\"))"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#image-example",
    "href": "slides/2_image_captioning_app.html#image-example",
    "title": "Gradio Image Captioning App",
    "section": "Image example",
    "text": "Image example\n\nFree images are available on: https://free-images.com/\n\n\nimage_url = \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"\n\ndisplay(IPython.display.Image(url=image_url))"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#model-output",
    "href": "slides/2_image_captioning_app.html#model-output",
    "title": "Gradio Image Captioning App",
    "section": "Model output",
    "text": "Model output\n\nget_completion(image_url)\n\n\n[{‘generated_text’: ‘a dog wearing a santa hat and a red scarf’}]"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#captioning-with-gr.interface",
    "href": "slides/2_image_captioning_app.html#captioning-with-gr.interface",
    "title": "Gradio Image Captioning App",
    "section": "Captioning with gr.Interface()",
    "text": "Captioning with gr.Interface()\n\ndef captioner(input):\n    result = get_completion(input)\n    return result[0]['generated_text']\n\n\ngr.close_all()\ndemo = gr.Interface(fn=captioner,\n                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n                    outputs=[gr.Textbox(label=\"Caption\")],\n                    title=\"Image Captioning with BLIP\",\n                    description=\"Caption any image using the BLIP model\",\n                    allow_flagging=\"never\"\n                    # examples=[\"your_image.jpeg\", \"your_image_2.jpeg\"]\n                    )\n\n\ndemo.launch(share=True)"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#gradio-interface",
    "href": "slides/2_image_captioning_app.html#gradio-interface",
    "title": "Gradio Image Captioning App",
    "section": "Gradio interface",
    "text": "Gradio interface"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#gradio-output",
    "href": "slides/2_image_captioning_app.html#gradio-output",
    "title": "Gradio Image Captioning App",
    "section": "Gradio output",
    "text": "Gradio output"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#api-version-optional",
    "href": "slides/2_image_captioning_app.html#api-version-optional",
    "title": "Gradio Image Captioning App",
    "section": "API version (optional)",
    "text": "API version (optional)\n\nOptional: Use this code if you want to use the API\n\n\n# converts image to base 64 format (required for API)\n\n\ndef image_to_base64_str(pil_image):\n    byte_arr = io.BytesIO()\n    pil_image.save(byte_arr, format='PNG')\n    byte_arr = byte_arr.getvalue()\n    return str(base64.b64encode(byte_arr).decode('utf-8'))\n\n\ndef captioner(image):\n    base64_image = image_to_base64_str(image)\n    result = get_completion(base64_image)\n    return result[0]['generated_text']\n\n\ngr.close_all()\ndemo = gr.Interface(fn=captioner,\n                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n                    outputs=[gr.Textbox(label=\"Caption\")],\n                    title=\"Image Captioning with BLIP\",\n                    description=\"Caption any image using the BLIP model\",\n                    allow_flagging=\"never\"\n                    # examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"]\n                    )\n\n\ndemo.launch(share=True, server_port=int(os.environ['PORT1']))"
  },
  {
    "objectID": "slides/2_image_captioning_app.html#close-all-connections",
    "href": "slides/2_image_captioning_app.html#close-all-connections",
    "title": "Gradio Image Captioning App",
    "section": "Close all connections",
    "text": "Close all connections\n\ngr.close_all()"
  },
  {
    "objectID": "slides/1_nlp_apps.html#api-code-optional",
    "href": "slides/1_nlp_apps.html#api-code-optional",
    "title": "Gradio NLP Apps",
    "section": "API code (optional)",
    "text": "API code (optional)\n\nIn our example: to run it via API, you could use an Inference Endpoint for the sshleifer/distilbart-cnn-12-6, a 306M parameter distilled model from facebook/bart-large-cnn.\n\n\n\n# # Helper function\n# import requests, json\n\n\n# #Summarization endpoint\n# def get_completion(inputs, parameters=None,ENDPOINT_URL=os.environ['HF_API_SUMMARY_BASE']):\n#     headers = {\n#       \"Authorization\": f\"Bearer {hf_api_key}\",\n#       \"Content-Type\": \"application/json\"\n#     }\n#     data = { \"inputs\": inputs }\n#     if parameters is not None:\n#         data.update({\"parameters\": parameters})\n#     response = requests.request(\"POST\",\n#                                 ENDPOINT_URL, headers=headers,\n#                                 data=json.dumps(data)\n#                                )\n#     return json.loads(response.content.decode(\"utf-8\"))"
  }
]