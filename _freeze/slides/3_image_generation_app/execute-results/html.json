{
  "hash": "8a0e81e8ef2be3b95aca3ea74868517a",
  "result": {
    "markdown": "---\ntitle: Gradio Image Creation App \ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: Gradio Tutorial 3\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# Image Generation App\n\nIn this tutorial, you'll create an image generation app with a Gradio interface.\n\n*This tutorial is mainly based on an excellent course provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearning.AI.*\n\n# Setup\n\n## Python\n\nLoad your HF API key and relevant Python libraries\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport io\nimport IPython.display\nfrom PIL import Image\nimport base64\nimport gradio as gr\nimport json\nfrom diffusers import DiffusionPipeline\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\nhf_api_key = os.environ['HF_API_KEY']\n```\n:::\n\n\n## Load model (only Apple Silicon)\n\n- In this example, we demonstrate how to use Stable Diffusion in Apple Silicon (M1/M2). \n- You'll find the Windows and Apple Intel version below.\n\n. . .\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Apple Silicon version\n\npipe = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n\npipe = pipe.to(\"mps\")\n\n# Recommended if your computer has < 64 GB of RAM\npipe.enable_attention_slicing()\n\n\ndef get_completion(prompt):\n    return pipe(prompt).images[0]\n\n```\n:::\n\n\n## Load Model (only Apple Intel and Windows)\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\npipe = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n\n\ndef get_completion(prompt):\n    return pipe(prompt).images[0]\n\n```\n:::\n\n\n## Optional: API-version {.smaller}\n\n- Only use this code if you want to use the API\n\n\n```{Python}\n\n# Helper function\nimport requests, json\n\n#Text-to-image endpoint\ndef get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n    headers = {\n      \"Authorization\": f\"Bearer {hf_api_key}\",\n      \"Content-Type\": \"application/json\"\n    }   \n    data = { \"inputs\": inputs }\n    if parameters is not None:\n        data.update({\"parameters\": parameters})\n    response = requests.request(\"POST\",\n                                ENDPOINT_URL,\n                                headers=headers,\n                                data=json.dumps(data))\n    return json.loads(response.content.decode(\"utf-8\"))\n```\n\n\n\n# Image Generation App\n\nBuilding an image generation app \n\n## Example prompt\n\n- Here we are going to run `runwayml/stable-diffusion-v1-5` using the `ðŸ§¨ diffusers` library.\n\n. . .\n\n\n```{Python}\nprompt = \"a dog in a park\"\n```\n\n\n## Result\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nresult = get_completion(prompt)\nresult\n```\n:::\n\n\n![](/images/dog_in_park.png)\n\n\n## Generating with `gr.Interface()` {.smaller}\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef generate(inputs):\n    output = get_completion(inputs)\n    return output\n\n\ngr.close_all()\ndemo = gr.Interface(fn=generate,\n                    inputs=[gr.Textbox(label=\"Your prompt\")],\n                    outputs=[gr.Image(label=\"Result\")],\n                    title=\"Image Generation with Stable Diffusion\",\n                    description=\"Generate any image with Stable Diffusion\",\n                    allow_flagging=\"never\",\n                    examples=[\n                        \"a scary cyborg wandering in the city of Stuttgart\", \"a red Jeep in a swimming pool\"]\n                    )\n\ndemo.launch(share=True)\n```\n:::\n\n\n## Gradio user interface\n\n![](/images/image_gen_1.png)\n\n## Output\n\n![](/images/image_gen_2.png)\n\n\n## Optional: API-Version {.smaller}\n\n\n```{Python}\nimport gradio as gr \n\n#A helper function to convert the PIL image to base64\n#so you can send it to the API\ndef base64_to_pil(img_base64):\n    base64_decoded = base64.b64decode(img_base64)\n    byte_stream = io.BytesIO(base64_decoded)\n    pil_image = Image.open(byte_stream)\n    return pil_image\n\ndef generate(prompt):\n    output = get_completion(prompt)\n    result_image = base64_to_pil(output)\n    return result_image\n\ngr.close_all()\ndemo = gr.Interface(fn=generate,\n                    inputs=[gr.Textbox(label=\"Your prompt\")],\n                    outputs=[gr.Image(label=\"Result\")],\n                    title=\"Image Generation with Stable Diffusion\",\n                    description=\"Generate any image with Stable Diffusion\",\n                    allow_flagging=\"never\",\n                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n\ndemo.launch(share=True, server_port=int(os.environ['PORT1']))\n```\n\n\n## Close apps\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndemo.close()\n```\n:::\n\n\n# Advanced User Interface\n\nBuilding a more advanced interface\n\n## Gradio app  {.smaller}\n\nNote: The following code for the local app mimics the code of the API-version as close as possible. \n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef get_completion(inputs, parameters=None):\n    data = {\"inputs\": inputs}\n    if parameters is not None:\n        data.update({\"parameters\": parameters})\n    response = json.dumps(data)\n    return pipe(response).images[0]\n\n\ndef generate(prompt, negative_prompt, steps, guidance, width, height):\n    params = {\n        \"negative_prompt\": negative_prompt,\n        \"num_inference_steps\": steps,\n        \"guidance_scale\": guidance,\n        \"width\": width,\n        \"height\": height\n    }\n\n    output = get_completion(prompt, params)\n    return output\n\n\ngr.close_all()\ndemo = gr.Interface(fn=generate,\n                    inputs=[\n                        gr.Textbox(label=\"Your prompt\"),\n                        gr.Textbox(label=\"Negative prompt\"),\n                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                                  info=\"In how many steps will the denoiser denoise the image?\"),\n                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n                                  info=\"Controls how much the text prompt influences the result\"),\n                        gr.Slider(label=\"Width\", minimum=64,\n                                  maximum=512, step=64, value=512),\n                        gr.Slider(label=\"Height\", minimum=64,\n                                  maximum=512, step=64, value=512),\n                    ],\n                    outputs=[gr.Image(label=\"Result\")],\n                    title=\"Image Generation with Stable Diffusion\",\n                    description=\"Generate any image with Stable Diffusion\",\n                    allow_flagging=\"never\"\n                    )\n\ndemo.launch(share=True)\n```\n:::\n\n\n## Gradio user interface\n\n![](/images/image_gen_3.png)\n\n\n## Model output\n\n![](/images/image_gen_4.png)\n\nðŸ¤”\n\n## Optional: API-version {.smaller}\n\n\n```{Python}\n\n#A helper function to convert the PIL image to base64 \n# so you can send it to the API\ndef base64_to_pil(img_base64):\n    base64_decoded = base64.b64decode(img_base64)\n    byte_stream = io.BytesIO(base64_decoded)\n    pil_image = Image.open(byte_stream)\n    return pil_image\n\ndef generate(prompt, negative_prompt, steps, guidance, width, height):\n    params = {\n        \"negative_prompt\": negative_prompt,\n        \"num_inference_steps\": steps,\n        \"guidance_scale\": guidance,\n        \"width\": width,\n        \"height\": height\n    }\n    \n    output = get_completion(prompt, params)\n    pil_image = base64_to_pil(output)\n    return pil_image\n\ngr.close_all()\ndemo = gr.Interface(fn=generate,\n                    inputs=[\n                        gr.Textbox(label=\"Your prompt\"),\n                        gr.Textbox(label=\"Negative prompt\"),\n                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                                 info=\"In how many steps will the denoiser denoise the image?\"),\n                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n                                  info=\"Controls how much the text prompt influences the result\"),\n                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n                    ],\n                    outputs=[gr.Image(label=\"Result\")],\n                    title=\"Image Generation with Stable Diffusion\",\n                    description=\"Generate any image with Stable Diffusion\",\n                    allow_flagging=\"never\"\n                    )\n\ndemo.launch(share=True, server_port=int(os.environ['PORT2']))\n```\n\n\n## Close apps\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndemo.close()\n```\n:::\n\n\n# Gradio Blocks\n\n## Gradio example with Blocks {.smaller}\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n    prompt = gr.Textbox(label=\"Your prompt\")\n    with gr.Row():\n        with gr.Column():\n            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                              info=\"In many steps will the denoiser denoise the image?\")\n            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n                                 info=\"Controls how much the text prompt influences the result\")\n            width = gr.Slider(label=\"Width\", minimum=64,\n                              maximum=512, step=64, value=512)\n            height = gr.Slider(label=\"Height\", minimum=64,\n                               maximum=512, step=64, value=512)\n            btn = gr.Button(\"Submit\")\n        with gr.Column():\n            output = gr.Image(label=\"Result\")\n\n    btn.click(fn=generate, inputs=[\n              prompt, negative_prompt, steps, guidance, width, height], outputs=[output])\ngr.close_all()\ndemo.launch(share=True)\n```\n:::\n\n\n## Gradio user interface\n\n![](/images/image_gen_5.png)\n\n## Optional: API Version {.smaller}\n\n\n```{Python}\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n    prompt = gr.Textbox(label=\"Your prompt\")\n    with gr.Row():\n        with gr.Column():\n            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                      info=\"In many steps will the denoiser denoise the image?\")\n            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n                      info=\"Controls how much the text prompt influences the result\")\n            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n            btn = gr.Button(\"Submit\")\n        with gr.Column():\n            output = gr.Image(label=\"Result\")\n\n    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\ngr.close_all()\ndemo.launch(share=True, server_port=int(os.environ['PORT3']))\n\n```\n\n\n## Gradio app with drop down menu {.smaller}\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n    with gr.Row():\n        with gr.Column(scale=4):\n            # Give prompt some real estate\n            prompt = gr.Textbox(label=\"Your prompt\")\n        with gr.Column(scale=1, min_width=50):\n            btn = gr.Button(\"Submit\")  # Submit button side by side!\n    with gr.Accordion(\"Advanced options\", open=False):  # Let's hide the advanced options!\n        negative_prompt = gr.Textbox(label=\"Negative prompt\")\n        with gr.Row():\n            with gr.Column():\n                steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                                  info=\"In many steps will the denoiser denoise the image?\")\n                guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n                                     info=\"Controls how much the text prompt influences the result\")\n            with gr.Column():\n                width = gr.Slider(label=\"Width\", minimum=64,\n                                  maximum=512, step=64, value=512)\n                height = gr.Slider(label=\"Height\", minimum=64,\n                                   maximum=512, step=64, value=512)\n    output = gr.Image(label=\"Result\")  # Move the output up too\n\n    btn.click(fn=generate, inputs=[\n              prompt, negative_prompt, steps, guidance, width, height], outputs=[output])\n\ngr.close_all()\ndemo.launch(share=True)\n```\n:::\n\n\n## Gradio user interface\n\n![](/images/gradio_app_7.png)\n\n\n## Optional: API Version  {.smaller}\n\n\n```{Python}\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n    with gr.Row():\n        with gr.Column(scale=4):\n            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n        with gr.Column(scale=1, min_width=50):\n            btn = gr.Button(\"Submit\") #Submit button side by side!\n    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n            with gr.Row():\n                with gr.Column():\n                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                      info=\"In many steps will the denoiser denoise the image?\")\n                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n                      info=\"Controls how much the text prompt influences the result\")\n                with gr.Column():\n                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n    output = gr.Image(label=\"Result\") #Move the output up too\n            \n    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n\ngr.close_all()\ndemo.launch(share=True, server_port=int(os.environ['PORT4']))\n```\n\n\n## Close all apps\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ngr.close_all()\n```\n:::\n\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** ðŸ‘\n\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-llm-gradio/)**\n\n",
    "supporting": [
      "3_image_generation_app_files"
    ],
    "filters": [],
    "includes": {}
  }
}